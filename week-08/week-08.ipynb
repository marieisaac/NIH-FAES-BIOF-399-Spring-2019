{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tqdm\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6c/4b/c38b5144cf167c4f52288517436ccafefe9dc01b8d1c190e18a6b154cd4a/tqdm-4.31.1-py2.py3-none-any.whl (48kB)\n",
      "\u001b[K    100% |████████████████████████████████| 51kB 5.6MB/s \n",
      "\u001b[?25hInstalling collected packages: tqdm\n",
      "Successfully installed tqdm-4.31.1\n",
      "\u001b[33mYou are using pip version 18.1, however version 19.0.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CIFAR-10 Dataset: 171MB [00:57, 2.95MB/s]                           \n"
     ]
    }
   ],
   "source": [
    "!pip install tqdm\n",
    "\n",
    "from urllib.request import urlretrieve\n",
    "from os.path import isfile, isdir\n",
    "from tqdm import tqdm \n",
    "import tarfile\n",
    "\n",
    "cifar10_dataset_folder_path = 'cifar-10-batches-py'\n",
    "\n",
    "class DownloadProgress(tqdm):\n",
    "    last_block = 0\n",
    "\n",
    "    def hook(self, block_num=1, block_size=1, total_size=None):\n",
    "        self.total = total_size\n",
    "        self.update((block_num - self.last_block) * block_size)\n",
    "        self.last_block = block_num\n",
    "\n",
    "\"\"\" \n",
    "    check if the data (zip) file is already downloaded\n",
    "    if not, download it from \"https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\" and save as cifar-10-python.tar.gz\n",
    "\"\"\"\n",
    "if not isfile('cifar-10-python.tar.gz'):\n",
    "    with DownloadProgress(unit='B', unit_scale=True, miniters=1, desc='CIFAR-10 Dataset') as pbar:\n",
    "        urlretrieve(\n",
    "            'https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz',\n",
    "            'cifar-10-python.tar.gz',\n",
    "            pbar.hook)\n",
    "\n",
    "if not isdir(cifar10_dataset_folder_path):\n",
    "    with tarfile.open('cifar-10-python.tar.gz') as tar:\n",
    "        tar.extractall()\n",
    "        tar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_label_names():\n",
    "    return ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cfar10_batch(cifar10_dataset_folder_path, batch_id):\n",
    "    with open(cifar10_dataset_folder_path + '/data_batch_' + str(batch_id), mode='rb') as file:\n",
    "        # note the encoding type is 'latin1'\n",
    "        batch = pickle.load(file, encoding='latin1')\n",
    "        \n",
    "    features = batch['data'].reshape((len(batch['data']), 3, 32, 32)).transpose(0, 2, 3, 1)\n",
    "    labels = batch['labels']\n",
    "        \n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_stats(cifar10_dataset_folder_path, batch_id, sample_id):\n",
    "    features, labels = load_cfar10_batch(cifar10_dataset_folder_path, batch_id)\n",
    "    \n",
    "    if not (0 <= sample_id < len(features)):\n",
    "        print('{} samples in batch {}.  {} is out of range.'.format(len(features), batch_id, sample_id))\n",
    "        return None\n",
    "\n",
    "    print('\\nStats of batch #{}:'.format(batch_id))\n",
    "    print('# of Samples: {}\\n'.format(len(features)))\n",
    "    \n",
    "    label_names = load_label_names()\n",
    "    label_counts = dict(zip(*np.unique(labels, return_counts=True)))\n",
    "    for key, value in label_counts.items():\n",
    "        print('Label Counts of [{}]({}) : {}'.format(key, label_names[key].upper(), value))\n",
    "    \n",
    "    sample_image = features[sample_id]\n",
    "    sample_label = labels[sample_id]\n",
    "    \n",
    "    print('\\nExample of Image {}:'.format(sample_id))\n",
    "    print('Image - Min Value: {} Max Value: {}'.format(sample_image.min(), sample_image.max()))\n",
    "    print('Image - Shape: {}'.format(sample_image.shape))\n",
    "    print('Label - Label Id: {} Name: {}'.format(sample_label, label_names[sample_label]))\n",
    "    \n",
    "    plt.imshow(sample_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stats of batch #3:\n",
      "# of Samples: 10000\n",
      "\n",
      "Label Counts of [0](AIRPLANE) : 994\n",
      "Label Counts of [1](AUTOMOBILE) : 1042\n",
      "Label Counts of [2](BIRD) : 965\n",
      "Label Counts of [3](CAT) : 997\n",
      "Label Counts of [4](DEER) : 990\n",
      "Label Counts of [5](DOG) : 1029\n",
      "Label Counts of [6](FROG) : 978\n",
      "Label Counts of [7](HORSE) : 1015\n",
      "Label Counts of [8](SHIP) : 961\n",
      "Label Counts of [9](TRUCK) : 1029\n",
      "\n",
      "Example of Image 7000:\n",
      "Image - Min Value: 24 Max Value: 252\n",
      "Image - Shape: (32, 32, 3)\n",
      "Label - Label Id: 0 Name: airplane\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 250,
       "width": 253
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Explore the dataset\n",
    "batch_id = 3\n",
    "sample_id = 7000\n",
    "display_stats(cifar10_dataset_folder_path, batch_id, sample_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(x):\n",
    "    \"\"\"\n",
    "        argument\n",
    "            - x: input image data in numpy array [32, 32, 3]\n",
    "        return\n",
    "            - normalized x \n",
    "    \"\"\"\n",
    "    min_val = np.min(x)\n",
    "    max_val = np.max(x)\n",
    "    x = (x-min_val) / (max_val-min_val)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(x):\n",
    "    \"\"\"\n",
    "        argument\n",
    "            - x: a list of labels\n",
    "        return\n",
    "            - one hot encoding matrix (number of labels, number of class)\n",
    "    \"\"\"\n",
    "    encoded = np.zeros((len(x), 10))\n",
    "    \n",
    "    for idx, val in enumerate(x):\n",
    "        encoded[idx][val] = 1\n",
    "    \n",
    "    return encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _preprocess_and_save(normalize, one_hot_encode, features, labels, filename):\n",
    "    features = normalize(features)\n",
    "    labels = one_hot_encode(labels)\n",
    "\n",
    "    pickle.dump((features, labels), open(filename, 'wb'))\n",
    "\n",
    "\n",
    "def preprocess_and_save_data(cifar10_dataset_folder_path, normalize, one_hot_encode):\n",
    "    n_batches = 5\n",
    "    valid_features = []\n",
    "    valid_labels = []\n",
    "\n",
    "    for batch_i in range(1, n_batches + 1):\n",
    "        features, labels = load_cfar10_batch(cifar10_dataset_folder_path, batch_i)\n",
    "        \n",
    "        # find index to be the point as validation data in the whole dataset of the batch (10%)\n",
    "        index_of_validation = int(len(features) * 0.1)\n",
    "\n",
    "        # preprocess the 90% of the whole dataset of the batch\n",
    "        # - normalize the features\n",
    "        # - one_hot_encode the lables\n",
    "        # - save in a new file named, \"preprocess_batch_\" + batch_number\n",
    "        # - each file for each batch\n",
    "        _preprocess_and_save(normalize, one_hot_encode,\n",
    "                             features[:-index_of_validation], labels[:-index_of_validation], \n",
    "                             'preprocess_batch_' + str(batch_i) + '.p')\n",
    "\n",
    "        # unlike the training dataset, validation dataset will be added through all batch dataset\n",
    "        # - take 10% of the whold dataset of the batch\n",
    "        # - add them into a list of\n",
    "        #   - valid_features\n",
    "        #   - valid_labels\n",
    "        valid_features.extend(features[-index_of_validation:])\n",
    "        valid_labels.extend(labels[-index_of_validation:])\n",
    "\n",
    "    # preprocess the all stacked validation dataset\n",
    "    _preprocess_and_save(normalize, one_hot_encode,\n",
    "                         np.array(valid_features), np.array(valid_labels),\n",
    "                         'preprocess_validation.p')\n",
    "\n",
    "    # load the test dataset\n",
    "    with open(cifar10_dataset_folder_path + '/test_batch', mode='rb') as file:\n",
    "        batch = pickle.load(file, encoding='latin1')\n",
    "\n",
    "    # preprocess the testing data\n",
    "    test_features = batch['data'].reshape((len(batch['data']), 3, 32, 32)).transpose(0, 2, 3, 1)\n",
    "    test_labels = batch['labels']\n",
    "\n",
    "    # Preprocess and Save all testing data\n",
    "    _preprocess_and_save(normalize, one_hot_encode,\n",
    "                         np.array(test_features), np.array(test_labels),\n",
    "                         'preprocess_training.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_and_save_data(cifar10_dataset_folder_path, normalize, one_hot_encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "valid_features, valid_labels = pickle.load(open('preprocess_validation.p', mode='rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow\n",
    "import tensorflow as tf\n",
    "\n",
    "# Inputs\n",
    "x = tf.placeholder(tf.float32, shape=(None, 32, 32, 3), name='input_x')\n",
    "y =  tf.placeholder(tf.float32, shape=(None, 10), name='output_y')\n",
    "keep_prob = tf.placeholder(tf.float32, name='keep_prob')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_net(x, keep_prob):\n",
    "    conv1_filter = tf.Variable(tf.truncated_normal(shape=[3, 3, 3, 64], mean=0, stddev=0.08))\n",
    "    conv2_filter = tf.Variable(tf.truncated_normal(shape=[3, 3, 64, 128], mean=0, stddev=0.08))\n",
    "    conv3_filter = tf.Variable(tf.truncated_normal(shape=[5, 5, 128, 256], mean=0, stddev=0.08))\n",
    "    conv4_filter = tf.Variable(tf.truncated_normal(shape=[5, 5, 256, 512], mean=0, stddev=0.08))\n",
    "\n",
    "    # 1, 2\n",
    "    conv1 = tf.nn.conv2d(x, conv1_filter, strides=[1,1,1,1], padding='SAME')\n",
    "    conv1 = tf.nn.relu(conv1)\n",
    "    conv1_pool = tf.nn.max_pool(conv1, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
    "    conv1_bn = tf.layers.batch_normalization(conv1_pool)\n",
    "\n",
    "    # 3, 4\n",
    "    conv2 = tf.nn.conv2d(conv1_bn, conv2_filter, strides=[1,1,1,1], padding='SAME')\n",
    "    conv2 = tf.nn.relu(conv2)\n",
    "    conv2_pool = tf.nn.max_pool(conv2, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')    \n",
    "    conv2_bn = tf.layers.batch_normalization(conv2_pool)\n",
    "  \n",
    "    # 5, 6\n",
    "    conv3 = tf.nn.conv2d(conv2_bn, conv3_filter, strides=[1,1,1,1], padding='SAME')\n",
    "    conv3 = tf.nn.relu(conv3)\n",
    "    conv3_pool = tf.nn.max_pool(conv3, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')  \n",
    "    conv3_bn = tf.layers.batch_normalization(conv3_pool)\n",
    "    \n",
    "    # 7, 8\n",
    "    conv4 = tf.nn.conv2d(conv3_bn, conv4_filter, strides=[1,1,1,1], padding='SAME')\n",
    "    conv4 = tf.nn.relu(conv4)\n",
    "    conv4_pool = tf.nn.max_pool(conv4, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
    "    conv4_bn = tf.layers.batch_normalization(conv4_pool)\n",
    "    \n",
    "    # 9\n",
    "    flat = tf.contrib.layers.flatten(conv4_bn)  \n",
    "\n",
    "    # 10\n",
    "    full1 = tf.contrib.layers.fully_connected(inputs=flat, num_outputs=128, activation_fn=tf.nn.relu)\n",
    "    full1 = tf.nn.dropout(full1, keep_prob)\n",
    "    full1 = tf.layers.batch_normalization(full1)\n",
    "    \n",
    "    # 11\n",
    "    full2 = tf.contrib.layers.fully_connected(inputs=full1, num_outputs=256, activation_fn=tf.nn.relu)\n",
    "    full2 = tf.nn.dropout(full2, keep_prob)\n",
    "    full2 = tf.layers.batch_normalization(full2)\n",
    "    \n",
    "    # 12\n",
    "    full3 = tf.contrib.layers.fully_connected(inputs=full2, num_outputs=512, activation_fn=tf.nn.relu)\n",
    "    full3 = tf.nn.dropout(full3, keep_prob)\n",
    "    full3 = tf.layers.batch_normalization(full3)    \n",
    "    \n",
    "    # 13\n",
    "    full4 = tf.contrib.layers.fully_connected(inputs=full3, num_outputs=1024, activation_fn=tf.nn.relu)\n",
    "    full4 = tf.nn.dropout(full4, keep_prob)\n",
    "    full4 = tf.layers.batch_normalization(full4)        \n",
    "    \n",
    "    # 14\n",
    "    out = tf.contrib.layers.fully_connected(inputs=full4, num_outputs=10, activation_fn=None)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = conv_net(x, keep_prob)\n",
    "model = tf.identity(logits, name='logits') # Name logits Tensor, so that can be loaded from disk after training\n",
    "\n",
    "# Loss and Optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# Accuracy\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_neural_network(session, optimizer, keep_probability, feature_batch, label_batch):\n",
    "    session.run(optimizer, \n",
    "                feed_dict={\n",
    "                    x: feature_batch,\n",
    "                    y: label_batch,\n",
    "                    keep_prob: keep_probability\n",
    "                })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_stats(session, feature_batch, label_batch, cost, accuracy):\n",
    "    loss = sess.run(cost, \n",
    "                    feed_dict={\n",
    "                        x: feature_batch,\n",
    "                        y: label_batch,\n",
    "                        keep_prob: 1.\n",
    "                    })\n",
    "    valid_acc = sess.run(accuracy, \n",
    "                         feed_dict={\n",
    "                             x: valid_features,\n",
    "                             y: valid_labels,\n",
    "                             keep_prob: 1.\n",
    "                         })\n",
    "    \n",
    "    print('Loss: {:>10.4f} Validation Accuracy: {:.6f}'.format(loss, valid_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_features_labels(features, labels, batch_size):\n",
    "    \"\"\"\n",
    "    Split features and labels into batches\n",
    "    \"\"\"\n",
    "    for start in range(0, len(features), batch_size):\n",
    "        end = min(start + batch_size, len(features))\n",
    "        yield features[start:end], labels[start:end]\n",
    "\n",
    "def load_preprocess_training_batch(batch_id, batch_size):\n",
    "    \"\"\"\n",
    "    Load the Preprocessed Training data and return them in batches of <batch_size> or less\n",
    "    \"\"\"\n",
    "    filename = 'preprocess_batch_' + str(batch_id) + '.p'\n",
    "    features, labels = pickle.load(open(filename, mode='rb'))\n",
    "\n",
    "    # Return the training data in batches of size <batch_size> or less\n",
    "    return batch_features_labels(features, labels, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Epoch  1, CIFAR-10 Batch 1:  Loss:     2.0611 Validation Accuracy: 0.253200\n",
      "Epoch  1, CIFAR-10 Batch 2:  Loss:     1.7514 Validation Accuracy: 0.305200\n",
      "Epoch  1, CIFAR-10 Batch 3:  Loss:     1.3271 Validation Accuracy: 0.411600\n",
      "Epoch  1, CIFAR-10 Batch 4:  Loss:     1.3210 Validation Accuracy: 0.470000\n",
      "Epoch  1, CIFAR-10 Batch 5:  Loss:     1.2884 Validation Accuracy: 0.492800\n",
      "Epoch  2, CIFAR-10 Batch 1:  Loss:     1.1703 Validation Accuracy: 0.529800\n",
      "Epoch  2, CIFAR-10 Batch 2:  Loss:     1.0595 Validation Accuracy: 0.527400\n",
      "Epoch  2, CIFAR-10 Batch 3:  Loss:     0.9014 Validation Accuracy: 0.546400\n",
      "Epoch  2, CIFAR-10 Batch 4:  Loss:     0.8656 Validation Accuracy: 0.612400\n",
      "Epoch  2, CIFAR-10 Batch 5:  Loss:     0.8172 Validation Accuracy: 0.638000\n",
      "Epoch  3, CIFAR-10 Batch 1:  Loss:     0.7619 Validation Accuracy: 0.658000\n",
      "Epoch  3, CIFAR-10 Batch 2:  Loss:     0.5682 Validation Accuracy: 0.664400\n",
      "Epoch  3, CIFAR-10 Batch 3:  Loss:     0.5174 Validation Accuracy: 0.685400\n",
      "Epoch  3, CIFAR-10 Batch 4:  Loss:     0.4535 Validation Accuracy: 0.688800\n",
      "Epoch  3, CIFAR-10 Batch 5:  Loss:     0.5268 Validation Accuracy: 0.676400\n",
      "Epoch  4, CIFAR-10 Batch 1:  Loss:     0.4652 Validation Accuracy: 0.697400\n",
      "Epoch  4, CIFAR-10 Batch 2:  Loss:     0.2911 Validation Accuracy: 0.705600\n",
      "Epoch  4, CIFAR-10 Batch 3:  Loss:     0.2894 Validation Accuracy: 0.681800\n",
      "Epoch  4, CIFAR-10 Batch 4:  Loss:     0.3152 Validation Accuracy: 0.693200\n",
      "Epoch  4, CIFAR-10 Batch 5:  Loss:     0.2479 Validation Accuracy: 0.712600\n",
      "Epoch  5, CIFAR-10 Batch 1:  Loss:     0.2302 Validation Accuracy: 0.703400\n",
      "Epoch  5, CIFAR-10 Batch 2:  Loss:     0.1437 Validation Accuracy: 0.729400\n",
      "Epoch  5, CIFAR-10 Batch 3:  Loss:     0.2510 Validation Accuracy: 0.693000\n",
      "Epoch  5, CIFAR-10 Batch 4:  Loss:     0.0904 Validation Accuracy: 0.718200\n",
      "Epoch  5, CIFAR-10 Batch 5:  Loss:     0.1191 Validation Accuracy: 0.722200\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "batch_size = 128\n",
    "keep_probability = 0.7\n",
    "learning_rate = 0.001\n",
    "\n",
    "save_model_path = './image_classification'\n",
    "\n",
    "print('Training...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        # Loop over all batches\n",
    "        n_batches = 5\n",
    "        for batch_i in range(1, n_batches + 1):\n",
    "            for batch_features, batch_labels in load_preprocess_training_batch(batch_i, batch_size):\n",
    "                train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "                \n",
    "            print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "            print_stats(sess, batch_features, batch_labels, cost, accuracy)\n",
    "            \n",
    "    # Save Model\n",
    "    saver = tf.train.Saver()\n",
    "    save_path = saver.save(sess, save_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
