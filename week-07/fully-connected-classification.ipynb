{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "!pip install tensorflow-gpu==2.0.0-alpha0\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install some libraries if not installed already\n",
    "!pip install --upgrade scikit-image \n",
    "!pip install imgaug\n",
    "!pip install pandas==0.23.4\n",
    "!pip install pydicom\n",
    "!pip install seaborn==0.9.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import some libraries we will use\n",
    "import os, sys, glob, csv, random\n",
    "import pydicom\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from skimage import io\n",
    "\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST handwritten digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the dataset if you don't have it already or on Colab - 1\n",
    "!git clone https://github.com/myleott/mnist_png.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the dataset if you don't have it already or on Colab - 2\n",
    "os.chdir('mnist_png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the dataset if you don't have it already or on Colab - 3\n",
    "!tar -xzf mnist_png.tar.gz\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_base_dir_tr = 'mnist_png' # or point to appropriate directory if you're on Biowulf and already have the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all images in the training set\n",
    "mnist_digits = dict.fromkeys(range(10))\n",
    "for num in range(10):\n",
    "    mnist_digits[num] = glob.glob(os.path.join(mnist_base_dir_tr, 'training', str(num), '*.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image):\n",
    "  image = tf.image.decode_jpeg(image, channels=1)\n",
    "  image = tf.image.resize(image, [28, 28])\n",
    "\n",
    "  return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_image(path):\n",
    "  image = tf.io.read_file(path)\n",
    "  return preprocess_image(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_image_paths = []\n",
    "all_image_labels = []\n",
    "for num in range(10):\n",
    "  all_image_paths += mnist_digits[num]\n",
    "  all_image_labels += [num]*len(mnist_digits[num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = tf.data.Dataset.from_tensor_slices((all_image_paths, all_image_labels))\n",
    "\n",
    "# The tuples are unpacked into the positional arguments of the mapped function \n",
    "def load_and_preprocess_from_path_label(path, label):\n",
    "  return load_and_preprocess_image(path), label\n",
    "\n",
    "image_label_ds = ds.map(load_and_preprocess_from_path_label)\n",
    "image_label_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "ds = image_label_ds.apply(\n",
    "  tf.data.experimental.shuffle_and_repeat(buffer_size=len(all_image_paths)))\n",
    "ds = ds.batch(BATCH_SIZE)\n",
    "ds = ds.prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(), \n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(ds, epochs=10, steps_per_epoch=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install PyTorch if not installed already\n",
    "!pip install torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import PyTorch and related libraries\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data.dataset import Dataset\n",
    "import torch.nn.parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transform = transforms.Compose([\n",
    "        transforms.Resize(28),\n",
    "        transforms.ToTensor(),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNIST_Dataset(Dataset):\n",
    "    '''RSNA Pneumonia Dataset'''\n",
    "    def __init__(self, image_paths, labels, transform=None):\n",
    "        \n",
    "        self.X = np.asarray(image_paths)\n",
    "        self.Y = np.asarray(labels)\n",
    "        \n",
    "        self.transform = transform;\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X);\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = Image.open(self.X[idx])\n",
    "        label = self.Y[idx];\n",
    "        \n",
    "        if self.transform:\n",
    "            item = self.transform(item);\n",
    "        \n",
    "        return (item, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train configs\n",
    "num_epochs = 10\n",
    "batch_size = 64\n",
    "learning_rate = 0.001\n",
    "num_workers = 4\n",
    "num_gpus = 1\n",
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MNIST_Dataset(all_image_paths, all_image_labels, data_transform)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True,\n",
    "                                           num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network with a fully connected layer\n",
    "class FC(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FC, self).__init__()\n",
    "        self.fc = nn.Linear(28*28, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = x\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define network and optimizer\n",
    "fc = FC().to(device);\n",
    "\n",
    "criterion = nn.CrossEntropyLoss();\n",
    "optimizer = torch.optim.Adam(fc.parameters(), lr=learning_rate);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "losses = [];\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = Variable(images.float()).to(device)\n",
    "        labels = Variable(labels).to(device)\n",
    "\n",
    "        # Forward + Backward + Optimize\n",
    "        optimizer.zero_grad()\n",
    "        outputs = fc(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        losses.append(loss.item());\n",
    "        \n",
    "        if (i+1) % 10 == 0:\n",
    "            print ('Epoch : %d/%d, Iter : %d/%d,  Loss: %.4f' \n",
    "                   %(epoch+1, num_epochs, i+1, len(train_dataset)//batch_size, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# report accuracy\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in train_loader:\n",
    "        images, labels = data\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = fc(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1: Try to improve the performance of the networks.\n",
    "# What are the first obvious things to do, and what can you do more?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2: Try to do the same for the chest x-ray dataset with three classes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
